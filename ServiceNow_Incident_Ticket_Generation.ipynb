{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4cc3c3-e343-4a30-9d12-b735ac4c9dd7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Getting the environment value from workflow using dbutils.widgets. By default it will be 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d46632-ec27-43ed-9a74-1549fb7724d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env=dbutils.widgets.text('env','')\n",
    "env=dbutils.widgets.get('env')\n",
    "if env=='qa' or env=='QA':\n",
    "    job_catalog='_qa'\n",
    "elif env=='prod'or env=='PROD':\n",
    "    job_catalog='_prod'\n",
    "else:\n",
    "    env='DEV'\n",
    "    job_catalog='_dev'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cac0bc0-b827-4cb6-9121-7d2df1f20454",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Checks the metadata table for any records that have failed status and verifies if incidents are already created for those records. \n",
    "- If incidents are created, then ignore and exit, otherwise, further check the incident table if there is any incident created for other tasks from the same job run. \n",
    "- If an incident is created then, get the incident number and check the status of the incident to ensure it is still active. \n",
    "- If the incident is closed, create a new incident, else update the activity log of the exisiting incident with the failed task info of the same job run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5e9d671-9c66-4093-8c82-b07d2b84484d",
     "showTitle": true,
     "title": "check if incident exists given the job_id and run_id are same. If so, append the new task info to the existing one rather than creating a new incident."
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def retrieve_taskinfo_from_metadata_table_check_incident(incident_url,access_token_url,client_id,client_secret,resource,urgency,impact,cmdb_ci,caller_id,location,assignment_group):\n",
    "\n",
    "\n",
    "    Query1=(f'''\n",
    "\n",
    "                select distinct * from\n",
    "                {job_catalog}._utils.metadata__execution m\n",
    "                left join {job_catalog}._utils.metadata___incidents i\n",
    "                    on m.job_id =i.job_id\n",
    "                    and m.run_id = i.run_id\n",
    "                    and m.task_id = i.task_id\n",
    "                where \n",
    "                m.LOAD_START_DT>=now()- INTERVAL 6 days \n",
    "                and m.JOB_STATUS='Failed'\n",
    "                and i.incident_number is  null\n",
    "                    \n",
    "                ''')\n",
    "      \n",
    "    query_data = spark.sql(Query1).collect()\n",
    "    \n",
    "    \n",
    "    if len(query_data)>0:\n",
    "        # incident doesn't exist but there are records that has failed\n",
    "\n",
    "        for row in query_data:\n",
    "        #print(row)\n",
    "            \n",
    "            job_id=row['JOB_ID']\n",
    "            run_id=row['RUN_ID']\n",
    "            task_id=row['TASK_ID']\n",
    "            task_info={\n",
    "                \n",
    "                'job_id':job_id,\n",
    "                'run_id':run_id,\n",
    "                'task_id':task_id,\n",
    "                'task_name':row['TASK_NAME'],\n",
    "                'Workspace_URL':row['WORKSPACE_URL'],\n",
    "                'notebook_path':row['NOTEBOOK_PATH'],\n",
    "                'result_state':row['JOB_STATUS'],\n",
    "                'state_message':row['EXCEPTION']\n",
    "\n",
    "                }\n",
    "            \n",
    "            task_info_short={\n",
    "           \n",
    "                'task_name':row['TASK_NAME'],\n",
    "                'result_state':row['JOB_STATUS'],\n",
    "                }\n",
    "            \n",
    "            description=json.dumps(task_info)\n",
    "            short_description=json.dumps(task_info_short)\n",
    "        \n",
    "            print(\"Incident is not yet created for the provided task. Check if a task already exists with the job_id and run_id\")\n",
    "            Query=(f'''\n",
    "                select distinct\n",
    "                    *\n",
    "                from\n",
    "                    {job_catalog}._utils.metadata__execution m\n",
    "                    left join {job_catalog}._utils.metadata___incidents i\n",
    "                    on m.job_id =i.job_id\n",
    "                    and m.run_id = i.run_id\n",
    "                    and i.incident_number is not null\n",
    "                where \n",
    "                i.job_id='{job_id}' and i.run_id='{run_id}' and i.task_id !='{task_id}'\n",
    "                    order by i.incident_number desc\n",
    "                    limit 1\n",
    "\n",
    "                ''')\n",
    "        \n",
    "            query_data2 = spark.sql(Query).collect()\n",
    "            \n",
    "            if len(query_data2)>0:\n",
    "                print(\"Incident already exists with given job_id and run_id, retrieve incident number;check the incident status\")\n",
    "                \n",
    "                incident_number=query_data2[0]['incident_number']\n",
    "                print(incident_number)\n",
    "\n",
    "                state=getincidentstatus(incident_url,incident_number,access_token_url,client_id,client_secret,resource)\n",
    "                print(state)\n",
    "                if state in ['800','900']:\n",
    "                    print('Incident is closed.Create new incident for the new task')\n",
    "                    create_servicenow_incident(incident_url,access_token_url,client_id,client_secret,resource,urgency,short_description,impact,cmdb_ci,caller_id,location,assignment_group,description,job_id,run_id,task_id)\n",
    "\n",
    "                else:\n",
    "                    print(\"update the existing incident\")\n",
    "                    \n",
    "                    updation_status=update_existing_incident(incident_url,incident_number,task_info,access_token_url,client_id,client_secret,resource)\n",
    "                    print(updation_status)\n",
    "                    if updation_status[0] ==200:\n",
    "                        print('--------incident updated-------------')\n",
    "                        insert_into_metadata__execution_failed_runs(job_id,run_id,task_id,incident_number)\n",
    "                        print('Incident details updated in incidents table')\n",
    "                    else:\n",
    "                        print('Error occured while updating the incident.')\n",
    "                        print(updation_status[1])\n",
    "                        print(task_info)\n",
    "                        \n",
    "                    \n",
    "            # No incident exists with the job_id and run_id combination. so create a new incident\n",
    "            else:\n",
    "                print(\"No incident exists with the smae job_id and run_id. proceed with incident creation\")\n",
    "                \n",
    "                create_status=create_servicenow_incident(incident_url,access_token_url,client_id,client_secret,resource,urgency,short_description,impact,cmdb_ci,caller_id,location,assignment_group,description,job_id,run_id,task_id)\n",
    "                print(create_status)\n",
    "                print(task_info)\n",
    "    \n",
    "    else:\n",
    "        print('No failed taks found or the incidents already exists for the failed tasks')\n",
    "        exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44020dd8-f310-40fb-b366-c9c1ded6a23a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Check the status of the incident to check whether it has been closed/ resolved or still active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf866efb-12ce-40bf-ba3b-1bdbf9e01a95",
     "showTitle": true,
     "title": "Get the status of the incident (closed /resolved/open)"
    }
   },
   "outputs": [],
   "source": [
    "import requests,json\n",
    "\n",
    "def getincidentstatus(incident_url,incident_number,access_token_url,client_id,client_secret,resource):\n",
    "    \n",
    "\n",
    "        #url=f'https://jnj-internal-development.apigee.net/apg-001-servicenow/v1/now/table/incident?sysparm_query=number={incident_number}'\n",
    "        \n",
    "        incident_url=incident_url.rstrip('/')\n",
    "        url=incident_url+'?sysparm_query=number='+incident_number\n",
    "        access_token=get_access_token(access_token_url,client_id,client_secret,resource)\n",
    "\n",
    "        headers={\n",
    "            'Accept':'application/json',\n",
    "            'Content-Type':'application/json',\n",
    "            'Authorization':f'Bearer {access_token}'\n",
    "        }\n",
    "\n",
    "        response=requests.get(url,headers=headers)\n",
    "\n",
    "        if response.status_code==200:\n",
    "            data=response.json().get('result')\n",
    "            print(data)\n",
    "            state=data[0]['state']\n",
    "            return state\n",
    "           \n",
    "        else:\n",
    "            print(\"error:\",response.status_code,response.text)\n",
    "            exit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301e2cb4-23e2-4ad0-946c-91cb18e592ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If the incident is still active, then go ahead with the updation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81af50e-636e-468d-9ef3-fee7163594f4",
     "showTitle": true,
     "title": "Update the new task info in  ServiceNow in comments field."
    }
   },
   "outputs": [],
   "source": [
    "import requests,json\n",
    " \n",
    "\n",
    "def update_existing_incident(incident_url,incident_number,task_info,access_token_url,client_id,client_secret,resource):\n",
    "\n",
    "    # Set the request parameters\n",
    "   \n",
    "    api_url=incident_url+incident_number\n",
    "    access_token=get_access_token(access_token_url,client_id,client_secret,resource)\n",
    "    # Set the updated field values for the incident\n",
    "    incident_data={\n",
    "    \"incident_object\" : {\n",
    "                \"comments\":json.dumps(task_info)\n",
    "                }\n",
    "    }\n",
    "    \n",
    "    # Set proper headers\n",
    "    headers = {'Authorization': f'Bearer {access_token}',\"Accept\":\"application/json\"}\n",
    "    \n",
    "    # Do the HTTP PUT request\n",
    "    response = requests.put(api_url, headers=headers, json=incident_data)\n",
    "    \n",
    "    # Check for HTTP codes other than 200\n",
    "    if response.status_code != 200: \n",
    "        print('Status:', response.status_code, 'Headers:', response.headers, 'Error Response:',response.json())\n",
    "        exit()\n",
    "    \n",
    "    # Decode the JSON response into a dictionary and use the data\n",
    "    else:\n",
    "        data = response.json()\n",
    "        print(\"Incident updated successfully\")\n",
    "        return response.status_code,data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eefbd91-353a-4dfb-9461-8334021f9407",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once the incident is successfully updated, insert the data into incidents table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add2c5df-576e-433b-b2ad-5909ebdd7beb",
     "showTitle": true,
     "title": "Insert new incident info to '_utils.metadata___incidents' table"
    }
   },
   "outputs": [],
   "source": [
    "def insert_into_metadata__execution_failed_runs(job_id,run_id,task_id,incident_number):\n",
    "\n",
    "    try:\n",
    "        query=f'''insert into {job_catalog}._utils.metadata___incidents(job_id,run_id,task_id,incident_number,insert_ts)\n",
    "        values('{job_id}','{run_id}','{task_id}','{incident_number}',CURRENT_TIMESTAMP()) '''\n",
    "        spark.sql(query)\n",
    "    except Exception as Error:\n",
    "      print(Error)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74484d58-8010-4005-8b8d-1d86a13fbc41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If an incident was not created and there are no incidents from the same job run, then create a new incident. Also, if there exists an incident, but it is closed or resolved, then go ahead with creating a new incident.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744eb1e2-9b8b-431e-96d2-6e9f770f6500",
     "showTitle": true,
     "title": "Creating ServiceNow incident"
    }
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def create_servicenow_incident(url,access_token_url,client_id,client_secret,resource,urgency,short_description,impact,cmdb_ci,caller_id,location,assignment_group,description,job_id,run_id,task_id):\n",
    "\n",
    "    access_token=get_access_token(access_token_url,client_id,client_secret,resource)\n",
    "   \n",
    "\n",
    "    headers={'Authorization': f'Bearer {access_token}',\n",
    "        'Content-Type':'application/json','Accept':'application/json'}\n",
    "\n",
    "    data={\n",
    "    \"incident_object\":{\n",
    "        \"urgency\":urgency,\n",
    "        \"short_description\":short_description,\n",
    "        \"impact\":impact,\n",
    "        \"cmdb_ci\":cmdb_ci,\n",
    "        \"caller_id\":caller_id,\n",
    "        \"location\": location,\n",
    "        \"assignment_group\":assignment_group,\n",
    "        \"description\":description\n",
    "        }\n",
    "    }\n",
    "    response=requests.post(url,headers=headers,data=json.dumps(data))\n",
    "    print(response)\n",
    "\n",
    "    #check for http codes other than 200\n",
    "\n",
    "    if response.status_code!=200:\n",
    "        print('Status:',response.status_code,'Headers:', response.headers, 'Error Response:',response.json())\n",
    "        exit()\n",
    "\n",
    "    data=response.json()    \n",
    "    incident=data['result']['return_response']['number']\n",
    "    print('---------------Inserting incident data into metadata__execution_failed_runs table ')\n",
    "    insert_into_metadata__execution_failed_runs(job_id,run_id,task_id,incident)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1db483f-4c7e-420d-9471-36226a70e51e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Get access token for the  API. Every time the notebook is run, a new access token is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3e72f05-4ecb-4463-8731-9dad8636e8e8",
     "showTitle": true,
     "title": "Obtaining access token"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_access_token(access_token_url,client_id,client_secret,resource):\n",
    "\n",
    "    headers={ 'Content-Type':'application/x-www-form-urlencoded'}\n",
    "    payload=  {\n",
    "    'f':'pjson',\n",
    "    'grant_type':'client_credentials',\n",
    "    'client_id':client_id,\n",
    "    'client_secret':client_secret,\n",
    "    'resource':resource\n",
    "\n",
    "          }\n",
    "    \n",
    "    try:\n",
    "\n",
    "        response=requests.post(access_token_url,headers=headers,data=payload)\n",
    "        if response.status_code==200:\n",
    "             token=response.json().get('access_token')\n",
    "             return (token)\n",
    "        else:\n",
    "            print(f'Failed to obtain access token. Status Code:{response.status_code}')\n",
    "            print(f'Response content: {response.content.decode()}')\n",
    "        \n",
    "    except Exception as e:\n",
    "         print(f'Error:{str(e)}') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2505c771-5c37-4c1d-8d6e-00691107d60d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "All the details required to create or update a incident can be retrieved from _workflow_integration_parameters table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744cefaa-e0d8-43ec-b97a-958930ac9519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_workflow_details(environment,var_name):\n",
    "  \n",
    "  try:\n",
    "    \n",
    "    Query = (f'''\n",
    "      select \n",
    "        *\n",
    "      from\n",
    "        {job_catalog}._utils._workflow_integration_parameters \n",
    "      where \n",
    "           upper(_Env) = upper('{environment}') and variable_name=('{var_name}')\n",
    "      ''')\n",
    "    \n",
    "    query_data = spark.sql(Query).collect()\n",
    "    print(query_data[0][2])\n",
    "    return query_data[0][2]\n",
    "  \n",
    "   \n",
    "  except Exception as Error:\n",
    "    print(Error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea21830-8c55-4690-95be-2491d6d71ec0",
     "showTitle": false,
     "title": ""
    }
   },
   
   "source": [
    "\n",
    "    incident_url=retrieve_workflow_details(env,'incident_url')\n",
    "    access_token_url=retrieve_workflow_details(env,'access_token_url')\n",
    "    client_id=retrieve_workflow_details(env,'client_id')\n",
    "    resource=retrieve_workflow_details(env,'resource')\n",
    "    scope_name=retrieve_workflow_details(env,'secret_scope_name')\n",
    "    secret_name=retrieve_workflow_details(env,'secret_name')\n",
    "    client_secret=dbutils.secrets.get(scope_name,secret_name)\n",
    "    urgency=retrieve_workflow_details(env,'urgency')\n",
    "    impact=retrieve_workflow_details(env,'impact')\n",
    "    cmdb_ci=retrieve_workflow_details(env,'cmdb_ci')\n",
    "    caller_id=retrieve_workflow_details(env,'caller_id')\n",
    "    location=retrieve_workflow_details(env,'location')\n",
    "    assignment_group=retrieve_workflow_details(env,'assignment_group')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112ddec2-a148-40f8-81b6-4747d7414842",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tasks_list=retrieve_taskinfo_from_metadata_table_check_incident(incident_url,access_token_url,client_id,client_secret,resource,urgency,impact,cmdb_ci,caller_id,location,assignment_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f506249-373e-48f5-a594-4b698f8a328d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "__Incident_Ticket_Generation",
   "widgets": {
    "env": {
     "currentValue": "",
     "nuid": "d11bd406-603b-456d-abf2-cfbe01240145",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "env",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
